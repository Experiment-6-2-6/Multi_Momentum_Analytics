---
title: "Methodology"
author: "Kristoff Dudek"
date: "2022-11-26"
output: html_document
---
*This document is a record of my thought processes and work path I have chosen for my analysis. For the stakeholder version of the report please see MM_ETF_Report*

# Introduction
The main goal of this work is an automation of all weekly tasks associated with managing my investment portfolio and simultanously show my abilities to potential employers.

# Assumptions and goals
* All data should be pulled from public, free sources.
* I am interested in weekly data only.
* All the ETFs are listed in GBX (British Pennies - standard on London Stock Exchange)
* The report should be in PDF format but with option for HTML too.
* There should be a kind of summary of situation and recommendation based on the analisys.
* In the PDF version  should be only 3 top momentum ETFs with global bonds and physical gold (5 in total).
* In HTML I would like to have an additional dynamic chart for the last year of calculated momentum leaders for HTML format.
* Additionally, I need the weekly ETF momentum calculations added every week to my Google Sheets.
* For obvious security reason I can't publish my Google credential here so the outcomes will be stored in my local SQL database.
* There is no data for SGLN ETF available on Yahoo Finance hence I need some robust substitute for it.
* The top one is recommended but not if a failsafe rule is triggered.
* As the failsafe rule I am going to use 30 weeks Exponential Moving Average EMA(30). Asset under it can not be recommended and if all are in negative then going to cash should be advised.

## Setting Up The Environment

I am using three packages:
* Quantmod for quantitative analyse
* Tidyverse for general data manipulation
* DBI for working with databases

At the moment, for the simplicity, I am going to work with a virtual DB (in memory only).

```{r}
install.packages("quantmod")
install.packages("tidyverse")
install.packages("RPostgreSQL")
library(quantmod)
library(tidyverse)
library(dplyr)
library(RPostgreSQL)
```
Preparing an data frame for final report table and an auxiliary data frame for raw data:
* Reading list of ETF names from CSV file
* creating empty data frame with as many collumns as are ETFs
* Naming the columns with ETF tickers
```{r}
tickers <- read_csv("ETFs.csv", col_names = FALSE, show_col_types = FALSE)  %>% as.character() # list of ETFs' tickers
final_df <- data.frame(matrix(ncol = length(tickers), nrow = 0))
names(final_df) <- tickers
auxiliary_df <- data.frame(matrix(ncol = length(tickers), nrow = 0))
names(auxiliary_df) <- tickers
dbWriteTable(connection, "CleanedRawData", auxiliary_df)
```
Preparing the SQL database:
* establishing the connection (DB is on free on-line server)
* limiting data pull to the last 3 years
* populating the auxiliary data frame:
  + looping using ETF list
  + getting data from Yahoo Finance
  + dropping all columns except adjusted price
* dropping any rows with NA
```{r}
connection <- dbConnect(
  RPostgreSQL::PostgreSQL(),
  user="Kristoff",
  password="Yeah, sure, like I would show it",
  host="db.bit.io",
  port=5432,
  dbname="Kristoff/ETFs")
starting_date = Sys.Date() - (3 * 365)
for (ticker in tickers)
{
  auxiliary_df[ticker] <- 
    getSymbols(ticker, from = starting_date, periodicity = "weekly", auto.apply = FALSE) %>% 
    ad()
}
auxiliary_df <- na.omit(auxiliary_df) %>% tail(104) # two years of data only
dbWriteTable(connection, "CleanedRawData", value = auxiliary_df, overwrite = TRUE, append = FALSE, row.names = FALSE)
```
If there is NA in any ETF's data I decided to drop whole row in df because I need the ETFs' momentum in relation to each other. That means it doesn't matter much if sometimes I have longer period for comparison as long as the period is exactly same for all the ETFs.

## THe calculations
* Calculating the momentum
* Transforming the result in to _common_ percentage with only 2 decimals
* Sending the results to the database
* Disconecting as all the rest can be done locally
```{r}
final_df <- ROC(auxiliary_df, n = 52, type = "discrete")
laplay(final_df, function(x) round(auxiliary_df * 100,2))
dbWriteTable(connection, "OneYearMomentum", final_df)
```
