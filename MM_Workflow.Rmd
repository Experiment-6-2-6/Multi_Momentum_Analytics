---
title: "Methodology"
author: "Kristoff Dudek"
date: "2022-11-26"
output: html_document
---
*This document is a record of my thought processes and work path I have chosen for my analysis. For the stakeholder version of the report please see MM_ETF_Report*

# Introduction
The main goal of this work is an automation of all weekly tasks associated with managing my investment portfolio and simultanously show my abilities to potential employers.

# Assumptions and goals
* All data should be pulled from public, free sources.
* All the ETFs are listed in GBX (British Pennies - standard on London Stock Exchange)
* The report should be in PDF format but with option for HTML too.
* There should be a kind of summary of situation and recommendation based on the analisys.
* In the PDF version  should be only 3 top momentum ETFs with global bonds and physical gold (5 in total).
* In HTML I would like to have an additional dynamic chart for the last year of calculated momentum leaders for HTML format.
* Additionally, I need the weekly ETF momentum calculations added every week to my Google Sheets.
* For obvious security reason I can't publish my Google credential here so the outcomes will be stored in my local SQL database.
* There is no data for SGLN ETF available on Yahoo Finance hence I need some robust substitute for it.
* The top one is recommended but not if a failsafe rule is triggered.
* As the failsafe rule I am going to use 30 weeks Exponential Moving Average EMA(30). Asset under it can not be recommended and if all are in negative then going to cash should be advised.

## Setting Up The Environment

I am using three packages:
* Quantmod for quantitative analyse
* Tidyverse for general data manipulation
* DBI for working with databases

At the moment, for the simplicity, I am going to work with a virtual DB (in memory only).

```{r}
install.packages("quantmod")
install.packages("tidyverse")
install.packages("RPostgreSQL")
library(quantmod)
library(tidyverse)
library(dplyr)
library(RPostgreSQL)
```
Preparing an data frame for final report table and an auxiliary data frame for raw data:
* Reading list of ETF names from CSV file
* creating empty data frame with as many collumns as are ETFs
* Naming the columns with ETF tickers
```{r}
tickers <- read_csv("ETFs.csv", col_names = FALSE, show_col_types = FALSE)  %>% as.character() # list of ETFs' tickers
ft_df <- data.frame(matrix(ncol = length(tickers), nrow = 0)) # ft_df final table data frame 
names(ft_df) <- tickers
rd_df <- data.frame(matrix(ncol = length(tickers), nrow = 0)) # rd_df raw data data frame 
names(rd_df) <- tickers
dbWriteTable(connection, "CleanedRawData", rd_df)
```
Preparing the SQL database:
* establishing the connection
* limiting data pull to the last 3 years
* populating the auxiliary data frame:
  + looping using ETF list
  + getting data from Yahoo Finance
  + dropping all columns except adjusted price
* dropping any rows with NA
```{r}
connection <- dbConnect(PostgreSQL, ":memory:")
starting_date = Sys.Date() - (3 * 365)
for (ticker in tickers)
{
  rd_df[ticker] <- 
    getSymbols(ticker, from = starting_date, auto.apply = FALSE) %>% 
    ad()
}
rd_df <- na.omit(rd_df)
```
If there is NA in any ETF's data I decided to drop whole row in df because I need the ETFs' momentum in relation to each other. That means it doesn't matter much if sometimes I have longer period for comparison as long as the period is exactly same for all the ETFs.
